{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae708ffb",
   "metadata": {},
   "source": [
    "# PoC - Portfolio Health Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8afe7d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, re, json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "from natsort import natsorted\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "try:\n",
    "    import openai\n",
    "except ImportError:\n",
    "    openai = None\n",
    "\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "except ImportError:\n",
    "    genai = None\n",
    "\n",
    "# We will use Gemini for this project since it has free API credits\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fb83b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "HEADER_PATTERN = re.compile(r\"^(From|To|Date|Subject|Cc):\\s*(.*)\")\n",
    "FORWARD_MARKER = \"--- Forwarded Message ---\"\n",
    "BASE_DATA_PATH = \"../AI_Developer\"\n",
    "OUTPUT_FILE = \"Portfolio Health Report.md\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7372badf",
   "metadata": {},
   "source": [
    "### Data Ingestion & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8446ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_colleagues(path):\n",
    "    \"Read the colleagues table and map multiple emails from the same person into one person_id.\"\n",
    "    \n",
    "    colleagues = []\n",
    "    name_to_id = {}\n",
    "    person_counter = 0\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line == \"Characters:\":\n",
    "                continue\n",
    "            \n",
    "            # Expected format: [Role]: [Name] ([Email])\n",
    "            try:\n",
    "                role, rest = line.split(\":\", 1)\n",
    "                name, email = rest.strip().split(\"(\")\n",
    "                email = email.strip(\")\").strip()\n",
    "                name = name.strip()\n",
    "                role = role.strip()\n",
    "\n",
    "                # Map duplicates to same ID\n",
    "                if name in name_to_id:\n",
    "                    person_id = name_to_id[name]\n",
    "                else:\n",
    "                    person_id = f\"person-{person_counter}\"\n",
    "                    name_to_id[name] = person_id\n",
    "                    person_counter += 1\n",
    "\n",
    "                colleagues += [{\"person_id\": person_id, \"role\": role, \"name\": name, \"email\": email}]\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Failed parsing line:\", line, e)\n",
    "\n",
    "    return pd.DataFrame(colleagues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "113e9491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anonymous_people(people_field, colleagues):\n",
    "    \"Normalize an email field value (e.g. 'Péter Kovács (peter@x.com)') into 'p1 Role1, p2 Role2, ...'.\"\n",
    "\n",
    "    if not people_field:\n",
    "        return people_field\n",
    "    \n",
    "    results = []\n",
    "    # Split multiple recipients by comma\n",
    "    for part in people_field.split(\",\"):\n",
    "        name = part.strip()\n",
    "\n",
    "        # Remove email if in parentheses or trailing\n",
    "        if \"(\" in name:\n",
    "            name = name.split(\"(\")[0].strip()\n",
    "        elif \"@\" in name:  # case with no parentheses but email\n",
    "            name = \" \".join(name.split()[:-1])\n",
    "\n",
    "        # Lookup in colleagues table\n",
    "        match = colleagues[colleagues[\"name\"] == name]\n",
    "        if not match.empty:\n",
    "            row = match.iloc[0]\n",
    "            results.append(f\"{row['person_id']} {row['role']}\")\n",
    "        else:\n",
    "            results.append(\"external external\")\n",
    "\n",
    "    return \", \".join(results)\n",
    "\n",
    "\n",
    "def parse_email_file(path, thread_id, colleagues):\n",
    "    \"Parse a raw email thread in a .txt file into structured emails (header + body).\"\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    emails = []\n",
    "    current_headers = {}\n",
    "    current_body = []\n",
    "    message_id = 0\n",
    "\n",
    "    def commit_email():\n",
    "        nonlocal current_headers, current_body, message_id\n",
    "        if current_headers and current_body:\n",
    "            from_field = get_anonymous_people(current_headers.get(\"From\", \"\"), colleagues)\n",
    "            to_field = get_anonymous_people(current_headers.get(\"To\", \"\"), colleagues)\n",
    "            cc_field = get_anonymous_people(current_headers.get(\"Cc\", \"\"), colleagues)\n",
    "\n",
    "            emails.append({\n",
    "                \"thread_id\": thread_id,\n",
    "                \"message_id\": f\"message-{message_id}\",\n",
    "                \"From\": from_field,\n",
    "                \"To\": to_field,\n",
    "                \"Cc\": cc_field,\n",
    "                \"Date\": current_headers.get(\"Date\", \"\"),\n",
    "                \"Subject\": current_headers.get(\"Subject\", \"\"),\n",
    "                \"Body\": \"\\n\".join(current_body).strip()\n",
    "            })\n",
    "            current_headers = {}\n",
    "            current_body = []\n",
    "            message_id += 1\n",
    "\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "\n",
    "        # Detect forwarded email marker\n",
    "        if stripped.startswith(FORWARD_MARKER):\n",
    "            commit_email()  # close out the current email\n",
    "            continue\n",
    "\n",
    "        # Detect header lines\n",
    "        header_match = HEADER_PATTERN.match(stripped)\n",
    "        if header_match:\n",
    "            key, value = header_match.groups()\n",
    "            current_headers[key] = value.strip()\n",
    "        else:\n",
    "            current_body.append(line.rstrip())\n",
    "\n",
    "    # Final commit for the last email\n",
    "    commit_email()\n",
    "\n",
    "    return emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc36dc9",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b72dba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_thread(emails):\n",
    "    \"Format emails into the canonical structure required by the prompt.\"\n",
    "\n",
    "    formatted = []\n",
    "    for email in emails:\n",
    "        formatted.append(\n",
    "            f\"Thread ID: {email['thread_id']}, \"\n",
    "            f\"Message ID: {email['message_id']}, \"\n",
    "            f\"From: {email['From']}, \"\n",
    "            f\"To: {email['To']}, \"\n",
    "            f\"Cc: {email['Cc']}, \"\n",
    "            f\"Date: {email['Date']}, \"\n",
    "            f\"Subject: {email['Subject']} \"\n",
    "            f\"Message: {email['Body']}\"\n",
    "        )\n",
    "    return \"\\n\\n\".join(formatted)\n",
    "\n",
    "def extract_json(text):\n",
    "    \"Extract JSON from model output that is wrapped in Markdown.\"\n",
    "\n",
    "    match = re.search(r\"(\\[.*\\]|\\{.*\\})\", text, re.DOTALL)\n",
    "    if match:\n",
    "        try:\n",
    "            return json.loads(match.group(1))\n",
    "        except json.JSONDecodeError:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "\n",
    "def classify_thread(emails, model_client):\n",
    "    \"Run classification on a single email thread.\"\n",
    "    \n",
    "    thread_text = format_thread(emails)\n",
    "\n",
    "    classification_prompt = f\"\"\"\n",
    "    You are an assistant that analyzes the full email thread and flags if the thread contains any attention flags that haven't been resolved.\n",
    "\n",
    "    Here are the attention flags:\n",
    "    - Unresolved High-Priority Issues:\n",
    "        - Crucial issue that pose a threat to the system\n",
    "        - Issue unresolved for a long period of time\n",
    "        - Issue that were identified by high role members\n",
    "    - Emerging Risks or Blockers:\n",
    "        - Issue which indicate no clear path to resolution\n",
    "        - Issue missing ownership\n",
    "\n",
    "    For each flagged issue output JSON object:\n",
    "    {{\n",
    "        \"title\": str,\n",
    "        \"attention_flag\": str,\n",
    "        \"priority\": \"low\" | \"medium\" | \"high\" | null,\n",
    "        \"owner\": str | null,\n",
    "        \"days_since_last_update\": int,\n",
    "        \"evidence_quote\": str,\n",
    "        \"evidence_location\": {{\"thread_id\": str, \"message_id\": str}},\n",
    "        \"confidence\": 0..1\n",
    "    }}\n",
    "\n",
    "    - Use ONLY the provided text.\n",
    "    - If uncertain, set fields to null, never invent.\n",
    "    - Consider the entire conversation to decide if an issue is unresolved.\n",
    "    - If no issues are found, return an empty list [].\n",
    "\n",
    "    Thread: \"{thread_text}\"\n",
    "    \"\"\"\n",
    "\n",
    "    # response = model_client.chat.completions.create(\n",
    "    #     model=\"gpt-4o-mini\",\n",
    "    #     messages=[{\"role\": \"user\", \"content\": classification_prompt}],\n",
    "    #     temperature=0,\n",
    "    # )\n",
    "    # response = response.choices[0].message[\"content\"]\n",
    "\n",
    "    resp = model_client.generate_content(classification_prompt)\n",
    "    response = resp.text\n",
    "\n",
    "    try:\n",
    "        flagged_issues = extract_json(response)\n",
    "    except Exception:\n",
    "        print(\"Main output format error\")\n",
    "        print(response)\n",
    "        flagged_issues = []\n",
    "\n",
    "    # Referee step: Verify flagged issues\n",
    "    referee_prompt = f\"\"\"\n",
    "    Given the thread of emails and flagged issues (with evidence and location) verify for each issue:\n",
    "        1. The evidence_quote is word for word in the thread.\n",
    "        2. The flagged issue has not been resolved within the thread.\n",
    "        3. The output format follows the expect format.\n",
    "\n",
    "    Expected format:\n",
    "    {{\n",
    "        \"title\": str,\n",
    "        \"attention_flag\": str,\n",
    "        \"priority\": \"low\" | \"medium\" | \"high\" | null,\n",
    "        \"owner\": str | null,\n",
    "        \"days_since_last_update\": int,\n",
    "        \"evidence_quote\": str,\n",
    "        \"evidence_location\": {{\"thread_id\": str, \"message_id\": str}},\n",
    "        \"confidence\": 0..1\n",
    "    }}\n",
    "\n",
    "    Return the same list of issues, but add a field {{\"verified\": True | False}} to each issue.\n",
    "\n",
    "    Thread: \"{thread_text}\"\n",
    "    Flagged issues: \"{json.dumps(flagged_issues, ensure_ascii=False)}\"\n",
    "    \"\"\"\n",
    "\n",
    "    # referee_response = model_client.chat.completions.create(\n",
    "    #     model=\"gpt-4o-mini\",\n",
    "    #     messages=[{\"role\": \"user\", \"content\": referee_prompt}],\n",
    "    #     temperature=0,\n",
    "    # )\n",
    "    # referee_response = referee_response.choices[0].message[\"content\"]\n",
    "\n",
    "    resp = model_client.generate_content(referee_prompt)\n",
    "    referee_response = resp.text\n",
    "\n",
    "    try:\n",
    "        verified_issues = extract_json(referee_response)\n",
    "        flagged_issues = [issue for issue in verified_issues if issue.get(\"verified\")]\n",
    "    except Exception:\n",
    "        print(\"Referee output format error\")\n",
    "        print(response)\n",
    "        flagged_issues = []\n",
    "\n",
    "    return flagged_issues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2252d2ad",
   "metadata": {},
   "source": [
    "### Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcf28135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_owner_name(issues, colleagues):\n",
    "    \"Replace anonymized owner IDs by their name\"\n",
    "\n",
    "    for issue in issues:\n",
    "        owner = issue.get(\"owner\")\n",
    "        if owner and owner.startswith(\"person-\"):\n",
    "            row = colleagues[colleagues[\"person_id\"] == owner.split()[0]]\n",
    "            if not row.empty:\n",
    "                issue[\"owner\"] = row.iloc[0][\"name\"]\n",
    "\n",
    "def write_report_md(attention_flags, output_path):\n",
    "    \"Writes the attention flags to a Markdown report file.\"\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"# Portfolio Health Report\\n\\n\")\n",
    "\n",
    "        if not attention_flags:\n",
    "            f.write(\"No urgent blockers or emerging risks detected.\\n\")\n",
    "            return\n",
    "\n",
    "        for idx, issue in enumerate(attention_flags, start=1):\n",
    "            f.write(f\"## Issue {idx}\\n\")\n",
    "            f.write(f\"- **Title:** {issue.get('title', 'N/A')}\\n\")\n",
    "            f.write(f\"- **Attention Flag:** {issue.get('attention_flag', 'N/A')}\\n\")\n",
    "            f.write(f\"- **Priority:** {issue.get('priority', 'N/A')}\\n\")\n",
    "            f.write(f\"- **Owner:** {issue.get('owner', 'N/A')}\\n\")\n",
    "            f.write(f\"- **Days Since Last Update:** {issue.get('days_since_last_update', 'N/A')}\\n\")\n",
    "            f.write(f\"- **Evidence Quote:** {issue.get('evidence_quote', 'N/A')}\\n\")\n",
    "            loc = issue.get(\"evidence_location\", {})\n",
    "            f.write(f\"- **Location:** {loc.get('thread_id', 'N/A')}, {loc.get('message_id', 'N/A')}\\n\")\n",
    "            f.write(f\"- **Confidence:** {issue.get('confidence', 'N/A')}\\n\")\n",
    "            f.write(\"\\n---\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddea8ce",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58bedf24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c8845111af4af8ab66da16c1f844f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colleagues = parse_colleagues(f\"{BASE_DATA_PATH}/Colleagues.txt\")\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "attention_flags = []\n",
    "thread_id = 1\n",
    "\n",
    "# This can be run concurrently with Spark\n",
    "for file in tqdm(natsorted(glob.glob(f\"{BASE_DATA_PATH}/email*.txt\"))):\n",
    "    emails = parse_email_file(file, f\"thread-{thread_id}\", colleagues)\n",
    "    flagged = classify_thread(emails, model)\n",
    "    if flagged:\n",
    "        attention_flags.extend(flagged)\n",
    "    thread_id += 1\n",
    "    time.sleep(15)  # Sleep to avoid API timing out\n",
    "\n",
    "resolve_owner_name(attention_flags, colleagues)\n",
    "\n",
    "write_report_md(attention_flags, OUTPUT_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
